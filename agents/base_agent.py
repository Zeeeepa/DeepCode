"""
åŸºç¡€Agentç±»

æ‰€æœ‰Agentçš„åŸºç¡€ç±»ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£å’Œé€šç”¨åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½:
- call_llm(): è°ƒç”¨LLMçš„ç»Ÿä¸€æ¥å£
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List
from .config import AgentConfig
from .utils import LLMClient


class BaseAgent(ABC):
    """
    AgentåŸºç¡€ç±»
    
    æ‰€æœ‰Agentéƒ½åº”è¯¥ç»§æ‰¿æ­¤ç±»ï¼Œå¹¶å®ç°æŠ½è±¡æ–¹æ³•ã€‚
    æä¾›äº†é…ç½®ç®¡ç†ã€LLMå®¢æˆ·ç«¯ç­‰é€šç”¨åŠŸèƒ½ã€‚
    """
    
    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–Agent
        
        å‚æ•°:
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        self.config = AgentConfig()
        self.llm_client = None
        self._setup_llm_client()

    def call_llm(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """
        è°ƒç”¨LLMçš„ç»Ÿä¸€æ¥å£ï¼ˆå¸¦è¾“å…¥é•¿åº¦æ£€æŸ¥å’Œé”™è¯¯å¤„ç†ï¼‰
        
        å‚æ•°:
            messages (list): æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ [{"role": "user", "content": "å†…å®¹"}]
            **kwargs: LLMå‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰
        
        è¿”å›:
            str: LLMçš„å“åº”å†…å®¹
        """
        if not self.llm_client:
            return "LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®"
        
        # æ£€æŸ¥è¾“å…¥é•¿åº¦
        total_length = sum(len(msg.get("content", "")) for msg in messages)
        print(f"ğŸ“ è¾“å…¥æ€»é•¿åº¦: {total_length:,} å­—ç¬¦")
        
        # å¦‚æœè¾“å…¥è¿‡é•¿ï¼Œå°è¯•æˆªæ–­
        MAX_INPUT_LENGTH = 120000  # 12ä¸‡å­—ç¬¦é™åˆ¶
        if total_length > MAX_INPUT_LENGTH:
            print(f"âš ï¸ è¾“å…¥è¿‡é•¿ ({total_length:,} > {MAX_INPUT_LENGTH:,})ï¼Œå°è¯•æˆªæ–­...")
            messages = self._truncate_messages(messages, MAX_INPUT_LENGTH)
            new_length = sum(len(msg.get("content", "")) for msg in messages)
            print(f"ğŸ“ æˆªæ–­åé•¿åº¦: {new_length:,} å­—ç¬¦")
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        llm_params = {
            "temperature": kwargs.get("temperature", self.config.get_config("temperature", 0.7)),
            "max_tokens": kwargs.get("max_tokens", self.config.get_config("max_tokens", 16384))
        }
        
        # æ·»åŠ å…¶ä»–å‚æ•°
        llm_params.update(kwargs)
        
        try:
            print(f"ğŸ¤– å¼€å§‹è°ƒç”¨LLM...")
            response = self.llm_client.chat_completion(messages, **llm_params)
            
            if "error" in response:
                error_msg = response['error']
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {error_msg}")
                return f"è°ƒç”¨å¤±è´¥: {error_msg}"
            
            if "choices" in response and len(response["choices"]) > 0:
                content = response["choices"][0]["message"]["content"]
                print(f"âœ… LLMå“åº”æˆåŠŸï¼Œé•¿åº¦: {len(content):,} å­—ç¬¦")
                return content
            else:
                print(f"âŒ æ— æ•ˆçš„APIå“åº”æ ¼å¼: {response}")
                return "æ— æ•ˆçš„APIå“åº”æ ¼å¼"
                
        except Exception as e:
            error_msg = f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}"
            print(f"ğŸ’¥ {error_msg}")
            return error_msg
    
    def _truncate_messages(self, messages: List[Dict[str, str]], max_length: int) -> List[Dict[str, str]]:
        """
        æˆªæ–­æ¶ˆæ¯ä»¥é€‚åº”é•¿åº¦é™åˆ¶
        
        ä¼˜å…ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€åçš„ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸­é—´å†…å®¹é€‚å½“æˆªæ–­
        """
        if not messages:
            return messages
        
        # è®¡ç®—å½“å‰æ€»é•¿åº¦
        current_length = sum(len(msg.get("content", "")) for msg in messages)
        if current_length <= max_length:
            return messages
        
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€æ¡ï¼‰
        truncated_messages = []
        system_msg = None
        user_msgs = []
        
        for msg in messages:
            if msg.get("role") == "system":
                system_msg = msg
            else:
                user_msgs.append(msg)
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if system_msg:
            truncated_messages.append(system_msg)
            remaining_length = max_length - len(system_msg.get("content", ""))
        else:
            remaining_length = max_length
        
        # å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œä»æœ€åä¸€æ¡å¼€å§‹ä¿ç•™
        for msg in reversed(user_msgs):
            content = msg.get("content", "")
            if len(content) <= remaining_length:
                truncated_messages.insert(-1 if system_msg else 0, msg)
                remaining_length -= len(content)
            else:
                # æˆªæ–­è¿™æ¡æ¶ˆæ¯
                truncated_content = content[:remaining_length-100] + "\n\n[... å†…å®¹å·²æˆªæ–­ ...]"
                truncated_msg = msg.copy()
                truncated_msg["content"] = truncated_content
                truncated_messages.insert(-1 if system_msg else 0, truncated_msg)
                break
        
        return truncated_messages

    @abstractmethod
    def process(self, input_data: Any) -> Any:
        """
        å¤„ç†è¾“å…¥æ•°æ®ï¼ˆæŠ½è±¡æ–¹æ³•ï¼‰
        
        å‚æ•°:
            input_data: è¾“å…¥æ•°æ®
        
        è¿”å›:
            Any: å¤„ç†ç»“æœ
        """
        pass

    def _setup_llm_client(self) -> None:
        """è®¾ç½®LLMå®¢æˆ·ç«¯"""
        try:
            api_key = self.config.get_config("api_key")
            base_url = self.config.get_config("base_url")
            model = self.config.get_config("model", "gpt-3.5-turbo")
            
            if api_key and base_url:
                self.llm_client = LLMClient(api_key, base_url, model)
            else:
                print("âš ï¸ è­¦å‘Š: ç¼ºå°‘APIé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ AGENT_API_KEY å’Œ AGENT_BASE_URL")
        except Exception as e:
            print(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}") 