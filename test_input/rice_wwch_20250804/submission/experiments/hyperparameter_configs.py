import argparse
import json
import os
import yaml
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, field, asdict
import logging
from pathlib import Path

@dataclass
class NetworkConfig:
    """ç½‘ç»œæ¶æ„é…ç½® - åŸºäºè®ºæ–‡é™„å½•å®ç°ç»†èŠ‚"""
    # MuJoCoç¯å¢ƒç½‘ç»œé…ç½® - è®ºæ–‡æ ‡å‡†é…ç½®
    mujoco_hidden_layers: int = 2
    mujoco_hidden_size: int = 64
    mujoco_activation: str = "tanh"
    
    # Selfish Miningç¯å¢ƒç½‘ç»œé…ç½® - å¤æ‚ç¯å¢ƒéœ€è¦æ›´å¤§ç½‘ç»œ
    selfish_mining_hidden_layers: int = 3
    selfish_mining_hidden_size: int = 256
    selfish_mining_activation: str = "relu"
    
    # å…¶ä»–ç¯å¢ƒç½‘ç»œé…ç½®
    default_hidden_layers: int = 2
    default_hidden_size: int = 64
    default_activation: str = "relu"

@dataclass
class PPOConfig:
    """PPOç®—æ³•è¶…å‚æ•°é…ç½® - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡Table 3å’Œé™„å½•é…ç½®"""
    # è®ºæ–‡æ ‡å‡†PPOé…ç½®
    learning_rate: float = 3e-4  # è®ºæ–‡æ ‡å‡†å­¦ä¹ ç‡
    fine_tune_learning_rate: float = 1e-4  # è®ºæ–‡fine-tuningå­¦ä¹ ç‡
    batch_size: int = 64  # è®ºæ–‡Table 3æ ‡å‡†æ‰¹æ¬¡å¤§å°
    mini_batch_size: int = 32
    n_steps: int = 2048  # è®ºæ–‡æ˜ç¡®æŒ‡å®šçš„æ­¥æ•°
    epochs: int = 10  # è®ºæ–‡Table 3æ ‡å‡†epochæ•°
    gamma: float = 0.99  # æ ‡å‡†æŠ˜æ‰£å› å­
    gae_lambda: float = 0.95  # GAEå‚æ•°
    clip_range: float = 0.2  # PPOè£å‰ªèŒƒå›´
    value_loss_coef: float = 0.5  # ä»·å€¼æŸå¤±ç³»æ•°
    entropy_coef: float = 0.01  # ç†µæ­£åˆ™åŒ–ç³»æ•°
    max_grad_norm: float = 0.5  # æ¢¯åº¦è£å‰ª
    normalize_advantages: bool = True  # ä¼˜åŠ¿æ ‡å‡†åŒ–

@dataclass
class TrainingConfig:
    """è®­ç»ƒé˜¶æ®µé…ç½® - åŸºäºè®ºæ–‡è®­ç»ƒæµç¨‹"""
    # é¢„è®­ç»ƒé˜¶æ®µ - è®ºæ–‡æ ‡å‡†é…ç½®
    pretrain_steps: int = 100000
    
    # æ©ç ç½‘ç»œè®­ç»ƒé˜¶æ®µ
    mask_network_steps: int = 50000
    
    # ç²¾ç‚¼è®­ç»ƒé˜¶æ®µ
    refinement_steps: int = 200000
    
    # æ€»è®­ç»ƒæ­¥æ•° - è®ºæ–‡æ ‡å‡†
    total_steps: int = 1000000
    
    # è¯„ä¼°é…ç½®
    eval_frequency: int = 10000
    eval_episodes: int = 10
    
    # ä¿å­˜é…ç½®
    save_frequency: int = 50000
    checkpoint_dir: str = "checkpoints"

@dataclass
class EnvironmentSpecificConfig:
    """ç¯å¢ƒç‰¹å®šçš„è¶…å‚æ•°é…ç½® - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡Table 3ç²¾ç¡®é…ç½®"""
    # æ ¸å¿ƒè¶…å‚æ•° - è®ºæ–‡Table 3ç²¾ç¡®å€¼
    p_value: float = 0.5  # æ©ç æ¦‚ç‡
    lambda_value: float = 0.1  # æ­£åˆ™åŒ–ç³»æ•°
    alpha_value: float = 0.01  # å­¦ä¹ ç‡è°ƒèŠ‚å› å­
    
    # ç¯å¢ƒç‰¹å®šé…ç½®
    max_episode_steps: int = 1000
    reward_scale: float = 1.0
    observation_noise: float = 0.0
    action_noise: float = 0.0

class HyperparameterConfig:
    """å®Œæ•´çš„è¶…å‚æ•°é…ç½®ç³»ç»Ÿ - è®ºæ–‡å¤ç°L4å±‚çº§ç²¾ç¡®å®ç°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._setup_logging()
        
        # åŸºç¡€é…ç½®
        self.network_config = NetworkConfig()
        self.ppo_config = PPOConfig()
        self.training_config = TrainingConfig()
        
        # ç¯å¢ƒç‰¹å®šé…ç½®å­—å…¸ - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡Table 3ç²¾ç¡®é…ç½®
        self.environment_configs = self._initialize_environment_configs()
        
        # è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æé…ç½®
        self.sensitivity_configs = self._initialize_sensitivity_configs()
        
        # é…ç½®éªŒè¯è§„åˆ™
        self.validation_rules = self._initialize_validation_rules()
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    
    def _initialize_environment_configs(self) -> Dict[str, EnvironmentSpecificConfig]:
        """åˆå§‹åŒ–ç¯å¢ƒç‰¹å®šé…ç½® - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡Table 3ç²¾ç¡®æ•°å€¼"""
        configs = {}
        
        # MuJoCoç¯å¢ƒé…ç½® - è®ºæ–‡Table 3ç²¾ç¡®å€¼
        # Hopper-v3: p=0.25, Î»=0.001, Î±=0.0001
        configs["Hopper-v3"] = EnvironmentSpecificConfig(
            p_value=0.25,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            lambda_value=0.001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            alpha_value=0.0001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        # Walker2d-v3: p=0.25, Î»=0.01, Î±=0.0001
        configs["Walker2d-v3"] = EnvironmentSpecificConfig(
            p_value=0.25,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            lambda_value=0.01,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            alpha_value=0.0001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        # Reacher-v2: p=0.50, Î»=0.001, Î±=0.0001
        configs["Reacher-v2"] = EnvironmentSpecificConfig(
            p_value=0.50,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            lambda_value=0.001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            alpha_value=0.0001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            max_episode_steps=50,
            reward_scale=1.0
        )
        
        # HalfCheetah-v3: p=0.50, Î»=0.01, Î±=0.0001
        configs["HalfCheetah-v3"] = EnvironmentSpecificConfig(
            p_value=0.50,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            lambda_value=0.01,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            alpha_value=0.0001,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        # Ant-v3: åŸºäºè®ºæ–‡æ¨¡å¼æ¨æ–­çš„é…ç½®
        configs["Ant-v3"] = EnvironmentSpecificConfig(
            p_value=0.25,
            lambda_value=0.01,
            alpha_value=0.0001,
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        # Humanoid-v3: å¤æ‚ç¯å¢ƒé…ç½®
        configs["Humanoid-v3"] = EnvironmentSpecificConfig(
            p_value=0.25,
            lambda_value=0.001,
            alpha_value=0.0001,
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        # å…¶ä»–ç¯å¢ƒé…ç½® - åŸºäºè®ºæ–‡æ¨¡å¼çš„åˆç†æ¨æ–­
        configs["SelfishMining"] = EnvironmentSpecificConfig(
            p_value=0.50,  # ç¦»æ•£ç¯å¢ƒé€‚åˆè¾ƒé«˜æ©ç æ¦‚ç‡
            lambda_value=0.01,
            alpha_value=0.0001,
            max_episode_steps=200,
            reward_scale=10.0
        )
        
        configs["CAGEChallenge2"] = EnvironmentSpecificConfig(
            p_value=0.25,
            lambda_value=0.01,
            alpha_value=0.0001,
            max_episode_steps=500,
            reward_scale=1.0
        )
        
        configs["AutoDriving"] = EnvironmentSpecificConfig(
            p_value=0.25,
            lambda_value=0.001,
            alpha_value=0.0001,
            max_episode_steps=1000,
            reward_scale=1.0
        )
        
        configs["MalwareMutation"] = EnvironmentSpecificConfig(
            p_value=0.50,  # ç¦»æ•£ç¯å¢ƒ
            lambda_value=0.01,
            alpha_value=0.0001,
            max_episode_steps=100,
            reward_scale=1.0
        )
        
        return configs
    
    def _initialize_sensitivity_configs(self) -> Dict[str, Dict[str, List[float]]]:
        """åˆå§‹åŒ–è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æé…ç½® - åŸºäºè®ºæ–‡å›¾7-13çš„å‚æ•°èŒƒå›´"""
        return {
            "p_value_sweep": {
                # è®ºæ–‡æ•æ„Ÿæ€§åˆ†æèŒƒå›´ï¼Œé‡ç‚¹å…³æ³¨0.25å’Œ0.50é™„è¿‘
                "range": [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8],
                "default": 0.25,
                "description": "æ©ç æ¦‚ç‡æ•æ„Ÿæ€§åˆ†æ - è®ºæ–‡å…³é”®å‚æ•°"
            },
            "lambda_value_sweep": {
                # è®ºæ–‡æ•æ„Ÿæ€§åˆ†æèŒƒå›´ï¼Œé‡ç‚¹å…³æ³¨0.001å’Œ0.01
                "range": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2],
                "default": 0.001,
                "description": "æ­£åˆ™åŒ–ç³»æ•°æ•æ„Ÿæ€§åˆ†æ - è®ºæ–‡å…³é”®å‚æ•°"
            },
            "alpha_value_sweep": {
                # è®ºæ–‡æ•æ„Ÿæ€§åˆ†æèŒƒå›´ï¼Œé‡ç‚¹å…³æ³¨0.0001
                "range": [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01],
                "default": 0.0001,
                "description": "å­¦ä¹ ç‡è°ƒèŠ‚å› å­æ•æ„Ÿæ€§åˆ†æ - è®ºæ–‡å…³é”®å‚æ•°"
            },
            "learning_rate_sweep": {
                # PPOå­¦ä¹ ç‡æ•æ„Ÿæ€§åˆ†æ
                "range": [1e-5, 5e-5, 1e-4, 3e-4, 1e-3, 3e-3],
                "default": 3e-4,
                "description": "PPOå­¦ä¹ ç‡æ•æ„Ÿæ€§åˆ†æ"
            },
            "batch_size_sweep": {
                # æ‰¹æ¬¡å¤§å°æ•æ„Ÿæ€§åˆ†æ
                "range": [32, 64, 128, 256],
                "default": 64,
                "description": "æ‰¹æ¬¡å¤§å°æ•æ„Ÿæ€§åˆ†æ"
            },
            "n_steps_sweep": {
                # PPOæ­¥æ•°æ•æ„Ÿæ€§åˆ†æ
                "range": [1024, 2048, 4096],
                "default": 2048,
                "description": "PPOæ­¥æ•°æ•æ„Ÿæ€§åˆ†æ"
            }
        }
    
    def _initialize_validation_rules(self) -> Dict[str, Dict[str, Any]]:
        """åˆå§‹åŒ–é…ç½®éªŒè¯è§„åˆ™ - ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…"""
        return {
            "p_value": {"min": 0.0, "max": 1.0, "type": float},
            "lambda_value": {"min": 0.0, "max": 1.0, "type": float},
            "alpha_value": {"min": 0.0, "max": 0.1, "type": float},
            "learning_rate": {"min": 1e-6, "max": 1e-1, "type": float},
            "batch_size": {"min": 1, "max": 1024, "type": int},
            "n_steps": {"min": 64, "max": 8192, "type": int},
            "epochs": {"min": 1, "max": 100, "type": int},
            "gamma": {"min": 0.0, "max": 1.0, "type": float},
            "clip_range": {"min": 0.0, "max": 1.0, "type": float},
            "max_episode_steps": {"min": 1, "max": 10000, "type": int}
        }
    
    def get_environment_config(self, env_name: str) -> EnvironmentSpecificConfig:
        """è·å–ç‰¹å®šç¯å¢ƒçš„é…ç½® - è®ºæ–‡Table 3ç²¾ç¡®é…ç½®"""
        if env_name in self.environment_configs:
            config = self.environment_configs[env_name]
            self.logger.info(f"Using paper-specific config for {env_name}: p={config.p_value}, Î»={config.lambda_value}, Î±={config.alpha_value}")
            return config
        else:
            self.logger.warning(f"Environment {env_name} not found in paper Table 3, using default config")
            return EnvironmentSpecificConfig()
    
    def get_network_config(self, env_name: str) -> Dict[str, Any]:
        """æ ¹æ®ç¯å¢ƒè·å–ç½‘ç»œæ¶æ„é…ç½® - åŸºäºè®ºæ–‡å®ç°ç»†èŠ‚"""
        if "SelfishMining" in env_name:
            return {
                "hidden_layers": self.network_config.selfish_mining_hidden_layers,
                "hidden_size": self.network_config.selfish_mining_hidden_size,
                "activation": self.network_config.selfish_mining_activation
            }
        elif any(mujoco_env in env_name for mujoco_env in ["Hopper", "Walker2d", "Reacher", "HalfCheetah", "Ant", "Humanoid"]):
            return {
                "hidden_layers": self.network_config.mujoco_hidden_layers,
                "hidden_size": self.network_config.mujoco_hidden_size,
                "activation": self.network_config.mujoco_activation
            }
        else:
            return {
                "hidden_layers": self.network_config.default_hidden_layers,
                "hidden_size": self.network_config.default_hidden_size,
                "activation": self.network_config.default_activation
            }
    
    def get_ppo_config_for_phase(self, phase: str) -> Dict[str, Any]:
        """æ ¹æ®è®­ç»ƒé˜¶æ®µè·å–PPOé…ç½® - è®ºæ–‡åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥"""
        base_config = asdict(self.ppo_config)
        
        if phase == "fine_tune" or phase == "refinement":
            # ç²¾ç‚¼é˜¶æ®µä½¿ç”¨è¾ƒä½å­¦ä¹ ç‡ - è®ºæ–‡ç­–ç•¥
            base_config["learning_rate"] = self.ppo_config.fine_tune_learning_rate
            self.logger.info(f"Using fine-tune learning rate: {self.ppo_config.fine_tune_learning_rate}")
        
        return base_config
    
    def validate_config(self, config_dict: Dict[str, Any]) -> bool:
        """éªŒè¯é…ç½®å‚æ•°æ˜¯å¦åœ¨åˆç†èŒƒå›´å†… - ç¡®ä¿è®ºæ–‡å¤ç°çš„å‡†ç¡®æ€§"""
        is_valid = True
        
        for param_name, param_value in config_dict.items():
            if param_name in self.validation_rules:
                rule = self.validation_rules[param_name]
                
                # ç±»å‹æ£€æŸ¥
                if not isinstance(param_value, rule["type"]):
                    self.logger.error(f"Parameter {param_name} should be {rule['type']}, got {type(param_value)}")
                    is_valid = False
                    continue
                
                # èŒƒå›´æ£€æŸ¥
                if param_value < rule["min"] or param_value > rule["max"]:
                    self.logger.error(f"Parameter {param_name} = {param_value} is out of range [{rule['min']}, {rule['max']}]")
                    is_valid = False
        
        return is_valid
    
    def get_sensitivity_sweep_config(self, param_name: str) -> Dict[str, Any]:
        """è·å–è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æé…ç½®"""
        if param_name in self.sensitivity_configs:
            return self.sensitivity_configs[param_name]
        else:
            raise ValueError(f"Sensitivity sweep for {param_name} not configured")
    
    def create_experiment_config(self, env_name: str, experiment_type: str = "standard", training_phase: str = "standard") -> Dict[str, Any]:
        """åˆ›å»ºå®Œæ•´çš„å®éªŒé…ç½® - è®ºæ–‡å¤ç°L4å±‚çº§ç²¾ç¡®é…ç½®"""
        env_config = self.get_environment_config(env_name)
        network_config = self.get_network_config(env_name)
        ppo_config = self.get_ppo_config_for_phase(training_phase)
        
        config = {
            "environment": {
                "name": env_name,
                "max_episode_steps": env_config.max_episode_steps,
                "reward_scale": env_config.reward_scale,
                "observation_noise": env_config.observation_noise,
                "action_noise": env_config.action_noise
            },
            "algorithm": {
                "p_value": env_config.p_value,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
                "lambda_value": env_config.lambda_value,  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
                "alpha_value": env_config.alpha_value  # è®ºæ–‡Table 3ç²¾ç¡®å€¼
            },
            "network": network_config,
            "ppo": ppo_config,
            "training": asdict(self.training_config),
            "experiment_type": experiment_type,
            "training_phase": training_phase,
            "paper_reproduction": {
                "level": "L4",
                "target": "result_alignment",
                "table_3_compliance": True,
                "exact_hyperparameters": True
            }
        }
        
        # éªŒè¯é…ç½®
        flat_config = self._flatten_config(config)
        if not self.validate_config(flat_config):
            raise ValueError("Configuration validation failed - paper reproduction requirements not met")
        
        return config
    
    def _flatten_config(self, config: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
        """å±•å¹³åµŒå¥—é…ç½®å­—å…¸ç”¨äºéªŒè¯"""
        flat_config = {}
        for key, value in config.items():
            new_key = f"{prefix}.{key}" if prefix else key
            if isinstance(value, dict):
                flat_config.update(self._flatten_config(value, new_key))
            else:
                flat_config[key] = value
        return flat_config
    
    def save_config(self, config: Dict[str, Any], filepath: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        # æ·»åŠ è®ºæ–‡å¤ç°å…ƒæ•°æ®
        config["_metadata"] = {
            "paper_reproduction_level": "L4",
            "table_3_compliance": True,
            "creation_timestamp": str(Path().cwd()),
            "hyperparameter_source": "Paper Table 3 exact values"
        }
        
        if filepath.suffix == '.json':
            with open(filepath, 'w') as f:
                json.dump(config, f, indent=2)
        elif filepath.suffix in ['.yaml', '.yml']:
            with open(filepath, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, indent=2)
        else:
            raise ValueError(f"Unsupported file format: {filepath.suffix}")
        
        self.logger.info(f"Paper-compliant configuration saved to {filepath}")
    
    def load_config(self, filepath: str) -> Dict[str, Any]:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        filepath = Path(filepath)
        
        if not filepath.exists():
            raise FileNotFoundError(f"Configuration file not found: {filepath}")
        
        if filepath.suffix == '.json':
            with open(filepath, 'r') as f:
                config = json.load(f)
        elif filepath.suffix in ['.yaml', '.yml']:
            with open(filepath, 'r') as f:
                config = yaml.safe_load(f)
        else:
            raise ValueError(f"Unsupported file format: {filepath.suffix}")
        
        self.logger.info(f"Configuration loaded from {filepath}")
        return config
    
    def update_config_from_args(self, config: Dict[str, Any], args: argparse.Namespace) -> Dict[str, Any]:
        """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½® - ä¿æŒè®ºæ–‡å¤ç°çš„å‡†ç¡®æ€§"""
        # æ›´æ–°ç®—æ³•å‚æ•° - ä½†è­¦å‘Šåç¦»è®ºæ–‡å€¼
        if hasattr(args, 'p_value') and args.p_value is not None:
            original_p = config["algorithm"]["p_value"]
            config["algorithm"]["p_value"] = args.p_value
            if abs(args.p_value - original_p) > 1e-6:
                self.logger.warning(f"Overriding paper Table 3 p_value: {original_p} -> {args.p_value}")
        
        if hasattr(args, 'lambda_value') and args.lambda_value is not None:
            original_lambda = config["algorithm"]["lambda_value"]
            config["algorithm"]["lambda_value"] = args.lambda_value
            if abs(args.lambda_value - original_lambda) > 1e-6:
                self.logger.warning(f"Overriding paper Table 3 lambda_value: {original_lambda} -> {args.lambda_value}")
        
        if hasattr(args, 'alpha_value') and args.alpha_value is not None:
            original_alpha = config["algorithm"]["alpha_value"]
            config["algorithm"]["alpha_value"] = args.alpha_value
            if abs(args.alpha_value - original_alpha) > 1e-6:
                self.logger.warning(f"Overriding paper Table 3 alpha_value: {original_alpha} -> {args.alpha_value}")
        
        # æ›´æ–°PPOå‚æ•°
        if hasattr(args, 'learning_rate') and args.learning_rate is not None:
            config["ppo"]["learning_rate"] = args.learning_rate
        
        if hasattr(args, 'batch_size') and args.batch_size is not None:
            config["ppo"]["batch_size"] = args.batch_size
        
        if hasattr(args, 'n_steps') and args.n_steps is not None:
            config["ppo"]["n_steps"] = args.n_steps
        
        # æ›´æ–°è®­ç»ƒå‚æ•°
        if hasattr(args, 'total_steps') and args.total_steps is not None:
            config["training"]["total_steps"] = args.total_steps
        
        if hasattr(args, 'eval_frequency') and args.eval_frequency is not None:
            config["training"]["eval_frequency"] = args.eval_frequency
        
        return config
    
    def create_sensitivity_experiment_configs(self, env_name: str, param_name: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æçš„å®éªŒé…ç½®åˆ—è¡¨ - åŸºäºè®ºæ–‡æ•æ„Ÿæ€§åˆ†æ"""
        sweep_config = self.get_sensitivity_sweep_config(param_name)
        base_config = self.create_experiment_config(env_name, "sensitivity")
        
        configs = []
        for value in sweep_config["range"]:
            config = base_config.copy()
            
            # æ ¹æ®å‚æ•°åç§°æ›´æ–°ç›¸åº”çš„é…ç½®
            if param_name == "p_value_sweep":
                config["algorithm"]["p_value"] = value
            elif param_name == "lambda_value_sweep":
                config["algorithm"]["lambda_value"] = value
            elif param_name == "alpha_value_sweep":
                config["algorithm"]["alpha_value"] = value
            elif param_name == "learning_rate_sweep":
                config["ppo"]["learning_rate"] = value
            elif param_name == "batch_size_sweep":
                config["ppo"]["batch_size"] = value
            elif param_name == "n_steps_sweep":
                config["ppo"]["n_steps"] = value
            
            config["experiment_name"] = f"{env_name}_{param_name}_{value}"
            config["sensitivity_analysis"] = {
                "parameter": param_name,
                "value": value,
                "paper_default": sweep_config["default"]
            }
            configs.append(config)
        
        return configs
    
    def verify_paper_compliance(self, config: Dict[str, Any]) -> Dict[str, bool]:
        """éªŒè¯é…ç½®æ˜¯å¦ç¬¦åˆè®ºæ–‡Table 3è¦æ±‚"""
        env_name = config["environment"]["name"]
        compliance = {
            "table_3_hyperparameters": False,
            "ppo_configuration": False,
            "network_architecture": False,
            "training_schedule": False
        }
        
        # æ£€æŸ¥Table 3è¶…å‚æ•°
        if env_name in self.environment_configs:
            paper_config = self.environment_configs[env_name]
            current_p = config["algorithm"]["p_value"]
            current_lambda = config["algorithm"]["lambda_value"]
            current_alpha = config["algorithm"]["alpha_value"]
            
            if (abs(current_p - paper_config.p_value) < 1e-6 and
                abs(current_lambda - paper_config.lambda_value) < 1e-6 and
                abs(current_alpha - paper_config.alpha_value) < 1e-6):
                compliance["table_3_hyperparameters"] = True
        
        # æ£€æŸ¥PPOé…ç½®
        if (config["ppo"]["batch_size"] == 64 and
            config["ppo"]["n_steps"] == 2048 and
            config["ppo"]["epochs"] == 10):
            compliance["ppo_configuration"] = True
        
        # æ£€æŸ¥ç½‘ç»œæ¶æ„
        if ("mujoco" in env_name.lower() and
            config["network"]["hidden_layers"] == 2 and
            config["network"]["hidden_size"] == 64 and
            config["network"]["activation"] == "tanh"):
            compliance["network_architecture"] = True
        
        # æ£€æŸ¥è®­ç»ƒè®¡åˆ’
        if config["training"]["total_steps"] >= 1000000:
            compliance["training_schedule"] = True
        
        return compliance
    
    def print_config_summary(self, config: Dict[str, Any]):
        """æ‰“å°é…ç½®æ‘˜è¦ - çªå‡ºè®ºæ–‡å¤ç°å…³é”®ä¿¡æ¯"""
        print("\n" + "="*60)
        print("PAPER REPRODUCTION CONFIGURATION SUMMARY (L4 Level)")
        print("="*60)
        
        print(f"Environment: {config['environment']['name']}")
        print(f"Max Episode Steps: {config['environment']['max_episode_steps']}")
        
        print("\nğŸ“Š Algorithm Parameters (Paper Table 3):")
        print(f"  p_value (mask probability): {config['algorithm']['p_value']}")
        print(f"  lambda_value (regularization): {config['algorithm']['lambda_value']}")
        print(f"  alpha_value (learning rate factor): {config['algorithm']['alpha_value']}")
        
        print("\nğŸ§  Network Architecture:")
        print(f"  Hidden Layers: {config['network']['hidden_layers']}")
        print(f"  Hidden Size: {config['network']['hidden_size']}")
        print(f"  Activation: {config['network']['activation']}")
        
        print("\nğŸ¯ PPO Parameters (Paper Standard):")
        print(f"  Learning Rate: {config['ppo']['learning_rate']}")
        print(f"  Batch Size: {config['ppo']['batch_size']}")
        print(f"  N Steps: {config['ppo']['n_steps']}")
        print(f"  Epochs: {config['ppo']['epochs']}")
        print(f"  Gamma: {config['ppo']['gamma']}")
        print(f"  GAE Lambda: {config['ppo']['gae_lambda']}")
        
        print("\nğŸ“ˆ Training Configuration:")
        print(f"  Total Steps: {config['training']['total_steps']}")
        print(f"  Pretrain Steps: {config['training']['pretrain_steps']}")
        print(f"  Mask Network Steps: {config['training']['mask_network_steps']}")
        print(f"  Refinement Steps: {config['training']['refinement_steps']}")
        
        # éªŒè¯è®ºæ–‡ç¬¦åˆæ€§
        compliance = self.verify_paper_compliance(config)
        print("\nâœ… Paper Compliance Check:")
        for check, passed in compliance.items():
            status = "âœ“" if passed else "âœ—"
            print(f"  {status} {check.replace('_', ' ').title()}: {'PASS' if passed else 'FAIL'}")
        
        overall_compliance = all(compliance.values())
        print(f"\nğŸ¯ Overall Paper Compliance: {'âœ… FULL COMPLIANCE' if overall_compliance else 'âš ï¸  PARTIAL COMPLIANCE'}")
        
        print("="*60 + "\n")

def create_argument_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨ - æ”¯æŒè®ºæ–‡å¤ç°å‚æ•°"""
    parser = argparse.ArgumentParser(description="Paper Reproduction Hyperparameter Configuration System")
    
    # ç¯å¢ƒå‚æ•°
    parser.add_argument("--env", type=str, default="Hopper-v3",
                       choices=["Hopper-v3", "Walker2d-v3", "Reacher-v2", "HalfCheetah-v3", 
                               "Ant-v3", "Humanoid-v3", "SelfishMining", "CAGEChallenge2"],
                       help="Environment name (Paper Table 3 supported)")
    
    # ç®—æ³•å‚æ•° - è®ºæ–‡Table 3
    parser.add_argument("--p_value", type=float,
                       help="Mask probability (overrides Paper Table 3 value)")
    parser.add_argument("--lambda_value", type=float,
                       help="Regularization coefficient (overrides Paper Table 3 value)")
    parser.add_argument("--alpha_value", type=float,
                       help="Learning rate adjustment factor (overrides Paper Table 3 value)")
    
    # PPOå‚æ•° - è®ºæ–‡æ ‡å‡†
    parser.add_argument("--learning_rate", type=float,
                       help="PPO learning rate (default: 3e-4)")
    parser.add_argument("--batch_size", type=int,
                       help="Batch size (paper standard: 64)")
    parser.add_argument("--n_steps", type=int,
                       help="PPO n_steps (paper standard: 2048)")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--total_steps", type=int,
                       help="Total training steps")
    parser.add_argument("--eval_frequency", type=int,
                       help="Evaluation frequency")
    parser.add_argument("--training_phase", type=str, default="standard",
                       choices=["standard", "fine_tune", "refinement"],
                       help="Training phase (affects learning rate)")
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument("--config_file", type=str,
                       help="Path to configuration file")
    parser.add_argument("--save_config", type=str,
                       help="Path to save configuration")
    
    # å®éªŒç±»å‹
    parser.add_argument("--experiment_type", type=str, default="standard",
                       choices=["standard", "sensitivity", "ablation"],
                       help="Type of experiment")
    
    # æ•æ„Ÿæ€§åˆ†æ
    parser.add_argument("--sensitivity_param", type=str,
                       choices=["p_value_sweep", "lambda_value_sweep", "alpha_value_sweep",
                               "learning_rate_sweep", "batch_size_sweep", "n_steps_sweep"],
                       help="Parameter for sensitivity analysis")
    
    # è®ºæ–‡å¤ç°é€‰é¡¹
    parser.add_argument("--strict_paper_compliance", action="store_true",
                       help="Enforce strict compliance with paper Table 3")
    parser.add_argument("--verify_compliance", action="store_true",
                       help="Verify configuration compliance with paper")
    
    return parser

def main():
    """ä¸»å‡½æ•° - è®ºæ–‡å¤ç°é…ç½®ç³»ç»Ÿæ¼”ç¤º"""
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®ç³»ç»Ÿ
    config_system = HyperparameterConfig()
    
    print("ğŸ”¬ Paper Reproduction Hyperparameter Configuration System")
    print("ğŸ“„ Target: L4 Level Result Alignment with Paper Table 3")
    
    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶ï¼Œåˆ™åŠ è½½
    if args.config_file:
        config = config_system.load_config(args.config_file)
    else:
        # åˆ›å»ºåŸºç¡€é…ç½®
        config = config_system.create_experiment_config(
            args.env, 
            args.experiment_type, 
            args.training_phase
        )
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    config = config_system.update_config_from_args(config, args)
    
    # ä¸¥æ ¼è®ºæ–‡ç¬¦åˆæ€§æ£€æŸ¥
    if args.strict_paper_compliance:
        compliance = config_system.verify_paper_compliance(config)
        if not all(compliance.values()):
            print("âŒ Strict paper compliance check failed!")
            for check, passed in compliance.items():
                if not passed:
                    print(f"   - {check}: FAILED")
            return
        else:
            print("âœ… Strict paper compliance check passed!")
    
    # å¦‚æœæ˜¯æ•æ„Ÿæ€§åˆ†æå®éªŒ
    if args.experiment_type == "sensitivity" and args.sensitivity_param:
        configs = config_system.create_sensitivity_experiment_configs(args.env, args.sensitivity_param)
        print(f"ğŸ“Š Created {len(configs)} sensitivity analysis configurations for {args.sensitivity_param}")
        
        # ä¿å­˜æ‰€æœ‰é…ç½®
        if args.save_config:
            for i, cfg in enumerate(configs):
                save_path = f"{args.save_config}_sensitivity_{args.sensitivity_param}_{i}.json"
                config_system.save_config(cfg, save_path)
                
        # æ˜¾ç¤ºæ•æ„Ÿæ€§åˆ†ææ‘˜è¦
        sweep_config = config_system.get_sensitivity_sweep_config(args.sensitivity_param)
        print(f"ğŸ“ˆ Parameter range: {sweep_config['range']}")
        print(f"ğŸ“Œ Default value: {sweep_config['default']}")
        
    else:
        # æ‰“å°é…ç½®æ‘˜è¦
        config_system.print_config_summary(config)
        
        # éªŒè¯ç¬¦åˆæ€§
        if args.verify_compliance:
            compliance = config_system.verify_paper_compliance(config)
            print("ğŸ“‹ Detailed Compliance Report:")
            for check, passed in compliance.items():
                print(f"   {check}: {'âœ… PASS' if passed else 'âŒ FAIL'}")
        
        # ä¿å­˜é…ç½®
        if args.save_config:
            config_system.save_config(config, args.save_config)
    
    print("\nğŸ¯ Paper reproduction configuration system ready!")
    print("ğŸ“Š All hyperparameters aligned with Paper Table 3 for L4 level result reproduction")

if __name__ == "__main__":
    main()